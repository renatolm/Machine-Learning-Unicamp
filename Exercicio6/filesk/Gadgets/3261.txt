Following last year’s Drive CX, Nvidia just announced an updated version of its computing platform for self-driving cars, the Drive PX 2. Compared to last year’s model, this is a much more powerful beast, able to process data from 12 video cameras and other sensors in real time to make educated driving decisions. The company calls it a supercomputer, and it’s the size of a lunchbox.
Behind the scene, the Drive PX 2 features 12 different cores representing 8 teraflops of calculation power, 24 deep learning tera operations per second. The company is using a 16nm architecture, and it’s a hungry beast as it requires 250W of power. Finally, Nvidia is using a liquid-cooling system. Because the PX 2 will be used in cars, that’s not too much of a problem and Nvidia argues that car manufacturers will just plug the device into their existing cooling solutions.
Nvidia co-founder and CEO Jen-Hsun Huang said that the PX 2 was as powerful as 150 MacBook Pros. The company is certainly comparing GPU power with the 13-inch MacBook Pro, which currently sports an Intel Iris Graphics 6100 chip. The PX 2 features two next-gen Tegra processors, as well as a Pascal-based GPU. In total, the system can push up to 8 teraflops and recognize up to 2,800 images per second using the AlexNet neural network-based deep learning algorithm.

The company also announced Nvidia Drivenet, its own deep neural network. It has the equivalent of 37 million neurons and was trained 120 million objects so far. Like other deep neural networks, it gets better over time.
Companies will be able to leverage this network, but Nvidia also insisted in saying that car makers would want to control their own neural network.
The company is promoting a platform approach, meaning that it wants to work with as many car makers as possible to kickstart their self-driving efforts. Volvo is going to be the first partner shipping Drive PX 2 in about 100 upcoming test cars. Nvidia has also partnered with Audi, Daimler, BMW and Ford to develop and test the PX 2.

As Huang showed during today’s keynote, all of this power is needed to enable self-driving cars to know enough about their environment — and interpret it — to safely drive in traffic. In one demo, Nvidia showed a new dashboard that can use this data to show drivers whether there are other cars around them at any given time. Thanks to this, “we soon won’t need rear-view mirrors anymore,” Huang joked.
As Nvidia clearly noted, though, identifying objects and planning basic paths is only the beginning. Looking ahead, making self-driving cars work in the real world also means that cars can recognize circumstances as well. Not every truck is the same, after all — some are ambulances, for example, and you better make space for those.

